import rouge
from nltk import download
from nltk.translate.bleu_score import sentence_bleu
from sklearn.metrics.pairwise import cosine_similarity
from transformers import AutoTokenizer, AutoModel
from .bedrock_integration import BedrockEvaluator
import torch
import nltk
import os
import ssl

class MetricCalculator:
    def __init__(self):
        # Set up SSL context for NLTK downloads
        try:
            _create_unverified_https_context = ssl._create_unverified_context
        except AttributeError:
            pass
        else:
            ssl._create_default_https_context = _create_unverified_https_context
        
        # Set NLTK data path to local directory
        nltk_data_dir = os.path.join(os.path.dirname(os.path.dirname(__file__)), 'nltk_data')
        os.makedirs(nltk_data_dir, exist_ok=True)
        nltk.data.path.append(nltk_data_dir)
        
        # Download necessary NLTK resources
        for resource in ['punkt_tab','punkt', 'wordnet', 'omw-1.4']:
            try:
                print('downloading nltk')
                nltk.download(resource, download_dir=nltk_data_dir, quiet=True)
            except Exception as e:
                print(f"Warning: Failed to download {resource}: {e}")
        
        # Initialize ROUGE
        self.rouge = rouge.Rouge()
        
        # Initialize semantic similarity model
        # self.tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/all-MiniLM-L6-v2')
        # self.model = AutoModel.from_pretrained('sentence-transformers/all-MiniLM-L6-v2')

        # Initialize Bedrock evaluator
        self.bedrock_evaluator = BedrockEvaluator()

    def calculate_rouge(self, generated_text, reference_text):
        """
        Calculate ROUGE scores
        
        :param generated_text: Text generated by the model
        :param reference_text: Ground truth text
        :return: ROUGE scores
        """
        try:
            rouge_scores = self.rouge.get_scores(generated_text, reference_text)[0]
            return {
                'rouge-1': rouge_scores['rouge-1']['f'],
                'rouge-2': rouge_scores['rouge-2']['f'],
                'rouge-l': rouge_scores['rouge-l']['f']

            }
        except Exception as e:
            return {'error': str(e)}

    def calculate_bleu(self, generated_text, reference_text):
        """
        Calculate BLEU score
        
        :param generated_text: Text generated by the model
        :param reference_text: Ground truth text
        :return: BLEU score
        """
        try:
            reference = [reference_text.split()]
            candidate = generated_text.split()
            bleu_score = sentence_bleu(reference, candidate)
            return bleu_score
        except Exception as e:
            return {'error': str(e)}

    def semantic_similarity(self, generated_text, reference_text , ):
        """
        Calculate semantic similarity using sentence transformers
        
        :param generated_text: Text generated by the model
        :param reference_text: Ground truth text
        :return: Cosine similarity score
        """

        try:
            # Tokenize and get embeddings
            # def get_embedding(text):
            #     inputs = self.tokenizer(text, return_tensors='pt', truncation=True, max_length=512)
            #     with torch.no_grad():
            #         model_output = self.model(**inputs)
            #     return self._mean_pooling(model_output, inputs['attention_mask'])

            gen_embedding = self.bedrock_evaluator.invoke_embedding(
                text=generated_text,
                model_name='amazon.titan-embed-text-v2'
            )

            ref_embedding = self.bedrock_evaluator.invoke_embedding(
                text=reference_text,
                model_name='amazon.titan-embed-text-v2'
            )

            # Calculate cosine similarity
            similarity = cosine_similarity(
                [gen_embedding], 
                [ref_embedding]
            )[0][0]

            return similarity
        except Exception as e:
            return {'error': str(e)}

    def _mean_pooling(self, model_output, attention_mask):
        """
        Perform mean pooling for sentence embeddings
        
        :param model_output: Model output
        :param attention_mask: Attention mask
        :return: Mean pooled embeddings
        """
        token_embeddings = model_output[0]
        input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()
        return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)

    def calculate_meteor_score(self, reference: str, hypothesis: str) -> float:
        """Calculate METEOR score for summary evaluation."""
        from nltk.translate.meteor_score import meteor_score
        from nltk.tokenize import word_tokenize

        reference_tokens = word_tokenize(reference)
        hypothesis_tokens = word_tokenize(hypothesis)
        return meteor_score([reference_tokens], hypothesis_tokens)